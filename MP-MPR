#!/usr/bin/env python
# coding: utf-8



def MarkovProcess(changes,P,states,start,discount,reward,print_text=False):
    import numpy as np
    import random
    # Changes = amount of times the process will change (integer)
    # P = transition matrix (matrix)
    # states = possible states (list)
    # reward = reward at each state (list of numerics values) - set as None for just a MP
    # start = start value in transition matrix (string) - set as None for just a MP
    # discount = discount factor between each state (numeric)
    path=[start]
    current_activity = start
    if reward != None:
        accumulated_reward = 0   
    if discount == None:
        discount = 1
    i = 0
    while i < changes:
        for j in range(len(P)):
            if current_activity == states[j]:
                #print("j:", j )
                RV = np.random.choice(states,replace=True,p=P[j])
                for k in range(len(P)):
                    if RV == states[k]:
                        if P[j][k] == 1 and k == j:
                            if print_text == True:
                                print("The procces reached the termination state", "'",states[j],"'", "after", i, "steps.")
                            i = changes
                            break
                        path.append(states[k])
                        current_activity = states[k]
                        if reward != None:
                            accumulated_reward += reward[k]
                            if i > 0:
                                accumulated_reward = accumulated_reward*discount
                        #print("k:", k)
                        break
                break
        i += 1
    if print_text == True:
        print("The path was:", path)
        if reward != None:
            print("The procces resulted in a reward of: ", accumulated_reward, ".")
    if reward != None:
        return(path,accumulated_reward)
    else:
        return(path)


# My Markov chain:
states=[["School", "Game", "Food", "Party"],[5, 3, 1, -4]]
P=[[0.5,0.1,0.2,0.2],[0,1,0,0],[0.3,0.1,0.3,0.3],[0,0.1,0.6,0.3]]


# Run the command as
q,z=MarkovProcess(20,P,states[0],states[0][0],1,states[1],print_text=True)

# Which will return something like:
The procces reached the termination state ' Game ' after 11 steps.
The path was: ['School', 'School', 'School', 'School', 'Party', 'Party', 'Food', 'Party', 'Party', 'Food', 'School', 'Game']
The procces resulted in a reward of:  9 .

# Or simulate the expected payoff as:

n = 5000
EV = 0
for i in range(n):
    q,z = MarkovProcess(10,P,states[0],states[0][0],1,states[1],print_text=False)
    EV += z
print(EV/n)

